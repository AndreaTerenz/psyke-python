{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PSyKE's demo\n",
    "\n",
    "Some imports."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b710e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from psyke.cart.predictor import CartPredictor\n",
    "\n",
    "from psyke import Extractor\n",
    "from psyke.regression.strategy import AdaptiveStrategy\n",
    "from psyke.regression import Grid, FeatureRanker, HyperCubeExtractor\n",
    "from psyke.utils.logic import pretty_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import iris dataset separating features and class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e46c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_iris(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rename of the features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d5afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace integer indices with the corresponding string class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f807185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         target\n0        setosa\n1        setosa\n2        setosa\n3        setosa\n4        setosa\n..          ...\n145  versicolor\n146  versicolor\n147  versicolor\n148  versicolor\n149  versicolor\n\n[150 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>versicolor</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y).replace({\"target\": {0: 'setosa', 1: 'virginica', 2: 'versicolor'}})\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac49b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     SepalLength  SepalWidth  PetalLength  PetalWidth        iris\n0            5.1         3.5          1.4         0.2      setosa\n1            4.9         3.0          1.4         0.2      setosa\n2            4.7         3.2          1.3         0.2      setosa\n3            4.6         3.1          1.5         0.2      setosa\n4            5.0         3.6          1.4         0.2      setosa\n..           ...         ...          ...         ...         ...\n145          6.7         3.0          5.2         2.3  versicolor\n146          6.3         2.5          5.0         1.9  versicolor\n147          6.5         3.0          5.2         2.0  versicolor\n148          6.2         3.4          5.4         2.3  versicolor\n149          5.9         3.0          5.1         1.8  versicolor\n\n[150 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLength</th>\n      <th>SepalWidth</th>\n      <th>PetalLength</th>\n      <th>PetalWidth</th>\n      <th>iris</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>versicolor</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = x.join(y)\n",
    "dataset.columns = [*dataset.columns[:-1], 'iris']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split between train and test set in a reproducible way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fc5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use as predictor a KNN with K = 7 and we train it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8a3128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9733333333333334"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = KNeighborsClassifier(n_neighbors=4)\n",
    "predictor.fit(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "predictor.score(test.iloc[:, :-1], test.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create an extractor that uses the CART algorithm and we extract prolog rules from our trained KNN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART performance (3 rules):\n",
      "Accuracy = 0.92\n",
      "Fidelity = 0.92\n",
      "\n",
      "\n",
      "CART extracted rules:\n",
      "\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, setosa) :-\n",
      "    PetalWidth =< 0.75.\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, virginica) :-\n",
      "    PetalWidth =< 1.55.\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, versicolor).\n"
     ]
    }
   ],
   "source": [
    "DTClassifier = DecisionTreeClassifier().fit(train.iloc[:, :-1], predictor.predict(train.iloc[:, :-1]))\n",
    "cart = Extractor.cart(CartPredictor(DTClassifier))\n",
    "theory_from_cart = cart.extract(train)\n",
    "print(f'CART performance ({cart.n_rules} rules):')\n",
    "print(f'Accuracy = {cart.accuracy(test):.2f}')\n",
    "print(f'Fidelity = {cart.accuracy(test, predictor):.2f}\\n')\n",
    "print('\\nCART extracted rules:\\n\\n' + pretty_theory(theory_from_cart))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a GridEx extractor to extract prolog rules from the same KNN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'true_divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_33340/549355453.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mranked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFeatureRanker\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrankings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mgridEx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mExtractor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgridex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAdaptiveStrategy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mranked\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.85\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m.1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_examples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtheory_from_gridEx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgridEx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m print('GridEx performance ({} rules):\\nAccuracy = {:.2f}\\nAccuracy fidelity = {:.2f}\\n'\n\u001B[0;32m      5\u001B[0m       .format(gridEx.n_rules, gridEx.accuracy(test), gridEx.accuracy(test, predictor)))\n",
      "\u001B[1;32m~\\Desktop\\psyke\\psyke-python\\psyke\\regression\\gridex\\__init__.py\u001B[0m in \u001B[0;36mextract\u001B[1;34m(self, dataframe)\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[0msurrounding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mHyperCube\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_surrounding_cube\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[0msurrounding\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_std\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mthreshold\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msurrounding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_theory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\psyke\\psyke-python\\psyke\\regression\\gridex\\__init__.py\u001B[0m in \u001B[0;36m_iterate\u001B[1;34m(self, surrounding, dataframe)\u001B[0m\n\u001B[0;32m     71\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m                         \u001B[0mfake\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfake\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcube\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin_examples\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__generator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m                         \u001B[0mcube\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfake\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredictor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m                         \u001B[0mto_split\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mcube\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mto_split\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_merge\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mto_split\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfake\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\psyke\\psyke-python\\psyke\\regression\\hypercube.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, dataset, predictor)\u001B[0m\n\u001B[0;32m    249\u001B[0m         \u001B[0mfiltered\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filter_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredictor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 251\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    252\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_diversity\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    253\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mmean\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36mmean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m   3417\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3419\u001B[1;33m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001B[0m\u001B[0;32m   3420\u001B[0m                           out=out, **kwargs)\n\u001B[0;32m   3421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    188\u001B[0m             \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mret\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mrcount\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 190\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mret\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mrcount\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    191\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    192\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: ufunc 'true_divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "ranked = FeatureRanker(x.columns).fit(predictor, x).rankings()\n",
    "gridEx = Extractor.gridex(predictor, Grid(1, AdaptiveStrategy(ranked, [(0.85, 8)])), threshold=.1, min_examples=1)\n",
    "theory_from_gridEx = gridEx.extract(train)\n",
    "print('GridEx performance ({} rules):\\nAccuracy = {:.2f}\\nAccuracy fidelity = {:.2f}\\n'\n",
    "      .format(gridEx.n_rules, gridEx.accuracy(test), gridEx.accuracy(test, predictor)))\n",
    "print('GridEx extracted rules:\\n\\n' + pretty_theory(theory_from_gridEx))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use CReEPy and CREAM cluster-based extractors to perform the extraction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CReEPy performance (3 rules):\n",
      "Accuracy = 0.79\n",
      "Fidelity = 0.81\n",
      "\n",
      "CReEPy extracted rules:\n",
      "\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, virginica) :-\n",
      "    SepalLength in [4.899999, 6.700001], SepalWidth in [2.199999, 3.200001], PetalLength in [2.999999, 5.000001], PetalWidth in [0.999999, 1.800001].\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, versicolor) :-\n",
      "    SepalLength in [4.899999, 7.700001], SepalWidth in [2.199999, 3.800001], PetalLength in [2.999999, 6.900001], PetalWidth in [0.999999, 2.500001].\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, setosa) :-\n",
      "    SepalLength in [4.399999, 7.900001], SepalWidth in [2.199999, 4.100001], PetalLength in [1.199999, 6.900001], PetalWidth in [0.099999, 2.500001].\n"
     ]
    }
   ],
   "source": [
    "creepy = Extractor.creepy(predictor, depth=2, error_threshold=0.1, output=HyperCubeExtractor.Target.CLASSIFICATION)\n",
    "theory_from_creepy = creepy.extract(train)\n",
    "print('CReEPy performance ({} rules):\\nAccuracy = {:.2f}\\nFidelity = {:.2f}\\n'\n",
    "      .format(creepy.n_rules, creepy.accuracy(test), creepy.accuracy(test, predictor)))\n",
    "print('CReEPy extracted rules:\\n\\n' + pretty_theory(theory_from_creepy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREAM performance (3 rules):\n",
      "Accuracy = 0.79\n",
      "Fidelity = 0.81\n",
      "\n",
      "CREAM extracted rules:\n",
      "\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, virginica) :-\n",
      "    SepalLength in [4.899999, 6.700001], SepalWidth in [2.199999, 3.200001], PetalLength in [2.999999, 5.000001], PetalWidth in [0.999999, 1.800001].\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, versicolor) :-\n",
      "    SepalLength in [4.899999, 7.700001], SepalWidth in [2.199999, 3.800001], PetalLength in [2.999999, 6.900001], PetalWidth in [0.999999, 2.500001].\n",
      "iris(PetalLength, PetalWidth, SepalLength, SepalWidth, setosa) :-\n",
      "    SepalLength in [4.399999, 7.900001], SepalWidth in [2.199999, 4.100001], PetalLength in [1.199999, 6.900001], PetalWidth in [0.099999, 2.500001].\n"
     ]
    }
   ],
   "source": [
    "cream = Extractor.cream(predictor, depth=2, error_threshold=0.1, output=HyperCubeExtractor.Target.CLASSIFICATION)\n",
    "theory_from_cream = cream.extract(train)\n",
    "print('CREAM performance ({} rules):\\nAccuracy = {:.2f}\\nFidelity = {:.2f}\\n'\n",
    "      .format(cream.n_rules, cream.accuracy(test), cream.accuracy(test, predictor)))\n",
    "print('CREAM extracted rules:\\n\\n' + pretty_theory(theory_from_cream))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}